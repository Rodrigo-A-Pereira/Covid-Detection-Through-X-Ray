{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "name": "TransferLearningVGG.ipynb",
            "provenance": [],
            "collapsed_sections": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "tURhgaPUnpE6"
            },
            "source": [
                "<h1>Inicializations</h1>"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "KxVkccNbmVGo",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 122
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586735435401,
                    "user_tz": -60,
                    "elapsed": 67937
                },
                "outputId": "818a6807-1c33-4dff-d1af-3b26820511ef"
            },
            "source": [
                "BASEDIR = '.'\n",
                "TRAINDATAPATH = 'aug_dataset_covid/train'\n",
                "TESTDATAPATH = 'aug_dataset_covid/test'\n",
                "VALIDDATAPATH = 'aug_dataset_covid/valid'"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "4ovlfLNXnt5E"
            },
            "source": [
                "Make necessary imports"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "tclJoEw-lLac",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586735442069,
                    "user_tz": -60,
                    "elapsed": 2748
                },
                "outputId": "495e701b-918a-4ad6-9d3c-dd14620482f4"
            },
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras import models\n",
                "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,\\\n",
                "                                    MaxPooling2D,BatchNormalization,\\\n",
                "                                    MaxPooling2D,AveragePooling2D,\\\n",
                "                                    GlobalMaxPooling2D,GlobalAveragePooling2D,\\\n",
                "                                    Concatenate,Input,ZeroPadding2D,Reshape\n",
                "                                    \n",
                "from keras.layers.merge import concatenate\n",
                "import numpy as np\n",
                "import time\n",
                "import os\n",
                "\n",
                "from keras.preprocessing.image import ImageDataGenerator\n",
                "from keras.preprocessing.image import img_to_array, load_img\n",
                "from tensorflow.keras.callbacks import TensorBoard\n",
                "\n",
                "from tensorflow.keras.applications.resnet import ResNet50\n",
                "from tensorflow.keras.preprocessing import image\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.optimizers import Adam \n",
                "from tensorflow.keras.applications import VGG16, VGG19\n",
                "from tensorflow.keras import optimizers"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "VrNA186keXoj"
            },
            "source": [
                "<b>Load for the first time the dataset</b>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "CMeCM9-re642"
            },
            "source": [
                "We first begin by defining the preprocesses that our data is going to suffer, in this case it suffers the recomended preprocess by VGG as well as the possibility of beeing introduced some small alterations on the original image so our model generalzes better during training (small rotations, shears, zooming and mirroring)\n",
                "\n",
                "We make use of the flow_from_directory method available to the ImageDataGenerator object we created. This function will look at the given directory and separate the images in 2 classes based on our subdirectories.\n",
                "\n",
                "The images are given on 224 by 224, since its the recomended size to feed to a VGG Net model.\n",
                "\n",
                "Since the generator is an iterator, the batch size decides how many elements are to be \"returned\" on each next() call.\n",
                "\n",
                "We also shuffle the data to avoid situations where the model receives to much of the same consecutive class, and ends up not generalizing but instead memorizing.\n",
                "\n",
                "Note: the validation is composed of 20% of the original training dataset"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "DYC44nL0NETI",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 68
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586697536626,
                    "user_tz": -60,
                    "elapsed": 6722
                },
                "outputId": "57d47a74-892d-4690-e430-9fde763d32c4"
            },
            "source": [
                "train_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "train_generator=train_datagen.flow_from_directory(TRAINDATAPATH, \n",
                "                                                 target_size=(224,224),\n",
                "                                                 batch_size=1,\n",
                "                                                 class_mode=\"binary\",\n",
                "                                                 shuffle=True,\n",
                "                                                  seed=42)\n",
                "\n",
                "\n",
                "valid_generator=train_datagen.flow_from_directory(VALIDDATAPATH, \n",
                "                                                 target_size=(224,224),\n",
                "                                                 batch_size=1,\n",
                "                                                 class_mode=\"binary\",\n",
                "                                                 shuffle=True,\n",
                "                                                  seed=42)\n",
                "\n",
                "\n",
                "eval_generator = train_datagen.flow_from_directory(TESTDATAPATH,\n",
                "                                                  target_size=(224,224),\n",
                "                                                  batch_size=1,\n",
                "                                                  shuffle=False,\n",
                "                                                  seed=42,\n",
                "                                                  class_mode=\"binary\")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "FrqKKLm-EHh2",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 34
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586697537872,
                    "user_tz": -60,
                    "elapsed": 598
                },
                "outputId": "990b0461-4509-48a2-f20d-fc2f7748f8f0"
            },
            "source": [
                "print(eval_generator.class_indices)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "P7jE8myiiNre"
            },
            "source": [
                "Function whose purpose is to plot the values of the train and test accuracies according to the epoch"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "ruTyY1hGgPLU"
            },
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "\n",
                "def plot_acc_loss(result, epochs):\n",
                "    acc = result.history['accuracy']\n",
                "    loss = result.history['loss']\n",
                "    val_acc = result.history['val_accuracy']\n",
                "    val_loss = result.history['val_loss']\n",
                "    plt.figure(figsize=(15, 5))\n",
                "    plt.subplot(121)\n",
                "    plt.plot(range(1,epochs), acc[1:], label='Train_acc')\n",
                "    plt.plot(range(1,epochs), val_acc[1:], label='Test_acc')\n",
                "    plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "    plt.subplot(122)\n",
                "    plt.plot(range(1,epochs), loss[1:], label='Train_loss')\n",
                "    plt.plot(range(1,epochs), val_loss[1:], label='Test_loss')\n",
                "    plt.title('Loss over ' + str(epochs) + ' Epochs', size=15)\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "    plt.show()"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "G-Si3Vpki3PT"
            },
            "source": [
                "Now that we verified that some results are obtained from the last train, we proceed to find the best hyper parameters:\n",
                "\n",
                "The followed parameters where testes for the following values:\n",
                "\n",
                "Number of dense layers : 1, 2, 3, 4\n",
                "\n",
                "Number of nodes per dense layer: 16, 32, 64, 128, 256\n",
                "\n",
                "Value of dropout: 0, 0.2, 0.5\n",
                "\n",
                "Batch Size: 1, 2, 3\n",
                "\n",
                "Number of epochs trained: 10. 20. 30"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "Fk1_nfUTlaVf",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 1000
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586648235618,
                    "user_tz": -60,
                    "elapsed": 837758
                },
                "outputId": "b80b557c-5f96-452e-fc10-6d787d00e074"
            },
            "source": [
                "from tensorflow.keras.applications.resnet import preprocess_input\n",
                "import os\n",
                "\n",
                "\n",
                "NUMBER_DENSE = [1,2]\n",
                "DENSE_NODES = [128,256,512]\n",
                "DROPOUT = [0,0.25,0.5]\n",
                "BATCH_SIZE = [2]\n",
                "EPOCHS = [10]\n",
                "\n",
                "\n",
                "for denseNumber in NUMBER_DENSE:\n",
                "  for denseNodes in DENSE_NODES:\n",
                "    for dropoutNumber in DROPOUT:\n",
                "      for batchSize in BATCH_SIZE:\n",
                "        for epochNumber in EPOCHS:\n",
                "        \n",
                "\n",
                "          print(\"denseNumber:\\t\",denseNumber)\n",
                "          print(\"denseNodes:\\t\",denseNodes)\n",
                "          print(\"dropoutNumber:\\t\",dropoutNumber)\n",
                "          print(\"batchSize:\\t\",batchSize)\n",
                "          print(\"epochNumber:\\t\",epochNumber)\n",
                "\n",
                "          nOfNew = -2 \n",
                "          base_model=VGG16(weights='imagenet',\n",
                "                  include_top=False,\n",
                "                  input_shape=(224, 224, 3))\n",
                "          base_model.trainable = False\n",
                "\n",
                "          x=base_model.output\n",
                "          x=Flatten()(x)\n",
                "          \n",
                "\n",
                "          for i in range(denseNumber):\n",
                "            print(denseNodes)\n",
                "            x=Dense(denseNodes,activation='relu')(x) \n",
                "            x=Dropout(dropoutNumber)(x) \n",
                "\n",
                "          preds=Dense(1,activation='sigmoid')(x)\n",
                "\n",
                "          model=Model(inputs=base_model.input,outputs=preds)\n",
                "\n",
                "          model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.0005),metrics=['accuracy'])\n",
                "\n",
                "          step_size_train=train_generator.n//train_generator.batch_size\n",
                "          step_size_valid=valid_generator.n//valid_generator.batch_size\n",
                "          history=model.fit_generator(train_generator,\n",
                "                              steps_per_epoch =step_size_train,\n",
                "                              validation_data = valid_generator,\n",
                "                              validation_steps = step_size_valid,\n",
                "                              epochs= epochNumber\n",
                "                              )\n",
                "          \n",
                "          plot_acc_loss(history, epochNumber)\n",
                "          \n",
                "          eval_generator.reset() \n",
                "          x = model.evaluate_generator(eval_generator,\n",
                "                           steps = np.ceil(len(eval_generator) / 1),\n",
                "                           use_multiprocessing = False,\n",
                "                           verbose = 1,\n",
                "                           workers=1\n",
                "                           )\n",
                "          print('Test loss:' , x[0])\n",
                "          print('Test accuracy:',x[1])\n",
                "\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "fLiZG5RCnFy4"
            },
            "source": [
                "denseNumber:\t 1<br>\n",
                "denseNodes:\t 128<br>\n",
                "dropoutNumber:\t 0.25<br>\n",
                "batchSize:\t 2<br>\n",
                "epochNumber:\t 10<br>\n",
                "<br>\n",
                "<b>Test loss:</b> 0.6569514274597168<br>\n",
                "<b>Test accuracy:</b> 0.8125<br>"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "UMeF0D7_13Gm",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 68
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586735468332,
                    "user_tz": -60,
                    "elapsed": 7504
                },
                "outputId": "c3490902-0e59-4dd1-82a2-0199095b6214"
            },
            "source": [
                "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=30,shear_range=0.25,zoom_range=0.1, horizontal_flip = True)\n",
                "\n",
                "train_generator=train_datagen.flow_from_directory(TRAINDATAPATH, \n",
                "                                                 target_size=(224,224),\n",
                "                                                 batch_size=1,\n",
                "                                                 class_mode=\"binary\",\n",
                "                                                 shuffle=True,\n",
                "                                                  seed=42)\n",
                "\n",
                "\n",
                "valid_generator=train_datagen.flow_from_directory(VALIDDATAPATH, \n",
                "                                                 target_size=(224,224),\n",
                "                                                 batch_size=1,\n",
                "                                                 class_mode=\"binary\",\n",
                "                                                 shuffle=True,\n",
                "                                                  seed=42)\n",
                "\n",
                "\n",
                "eval_generator = train_datagen.flow_from_directory(TESTDATAPATH,\n",
                "                                                  target_size=(224,224),\n",
                "                                                  batch_size=1,\n",
                "                                                  shuffle=False,\n",
                "                                                  seed=42,\n",
                "                                                  class_mode=\"binary\")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "C4I4Se6YxlS7",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 819
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586735802584,
                    "user_tz": -60,
                    "elapsed": 326036
                },
                "outputId": "702462d2-05bf-49ab-ea05-f8ffc7cca104"
            },
            "source": [
                "denseNumber = 1\n",
                "denseNodes = 128\n",
                "dropoutNumber = 0.3\n",
                "batchSize = 2\n",
                "epochNumber = 20\n",
                "\n",
                "base_model=VGG16(weights='imagenet',\n",
                "                  include_top=False,\n",
                "                  input_shape=(224, 224, 3))\n",
                "base_model.trainable = False\n",
                "\n",
                "x=base_model.output\n",
                "x=Flatten()(x)\n",
                "\n",
                "\n",
                "for i in range(denseNumber):\n",
                "  print(denseNodes)\n",
                "  x=Dense(denseNodes,activation='relu')(x) \n",
                "  x=Dropout(dropoutNumber)(x) \n",
                "\n",
                "preds=Dense(1,activation='sigmoid')(x)\n",
                "\n",
                "model=Model(inputs=base_model.input,outputs=preds)\n",
                "\n",
                "model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.0003),metrics=['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
                "step_size_train=train_generator.n//train_generator.batch_size\n",
                "step_size_valid=valid_generator.n//valid_generator.batch_size\n",
                "history=model.fit_generator(train_generator,\n",
                "                    steps_per_epoch =step_size_train,\n",
                "                    validation_data = valid_generator,\n",
                "                    validation_steps = step_size_valid,\n",
                "                    epochs= epochNumber\n",
                "                    )"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "zecizGLB4WjS",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 320
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586736137882,
                    "user_tz": -60,
                    "elapsed": 1402
                },
                "outputId": "29d857bb-603c-486b-d0a1-f53bd611b86f"
            },
            "source": [
                "   plot_acc_loss(history, epochNumber)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "QsFLlyJP1Tpb"
            },
            "source": [
                "We proceed to test the model against the test set (20% of the original dataset)"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "HdZyYelG0A5H",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 190
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586736184361,
                    "user_tz": -60,
                    "elapsed": 41589
                },
                "outputId": "8f40970e-c769-4d15-ca39-f9d582b223a0"
            },
            "source": [
                "eval_generator.reset() \n",
                "x= model.evaluate_generator(eval_generator,\n",
                "                  steps = np.ceil(len(eval_generator) / 1),\n",
                "                  use_multiprocessing = False,\n",
                "                  verbose = 1,\n",
                "                  workers=1\n",
                "                  )\n",
                "print('Test loss:' , x[0])\n",
                "print('Test accuracy:',x[1])\n",
                "print('Test precision:', x[2])\n",
                "print('Test Recall:',x[3])\n",
                "print('Test F1 Score: ',2*(x[2]*x[3])/(x[2]+x[3]))"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "hpXuKY26yBtQ",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 122
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586736194446,
                    "user_tz": -60,
                    "elapsed": 2827
                },
                "outputId": "bda5afbf-6c5a-40e9-e265-e582f0a0855f"
            },
            "source": [
                "eval_generator.reset()  \n",
                "pred = model.predict_generator(eval_generator,steps = np.ceil(len(eval_generator) / 1),verbose=1)\n",
                "print(\"Predictions finished\")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "MOnSFun2hjNP"
            },
            "source": [
                "Display Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "HF-zF_TGy8gT",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 354
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586736199708,
                    "user_tz": -60,
                    "elapsed": 1551
                },
                "outputId": "cdd1ade2-6698-4938-e550-cfea5c508085"
            },
            "source": [
                "import seaborn as sn\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "trueP= x[4]\n",
                "trueN = x[5]\n",
                "falseP = x[6]\n",
                "falseN = x[7]\n",
                "array = [[trueP,falseP],\n",
                "         [falseN,trueN]]\n",
                "\n",
                "array = [[trueP,falseP], [falseN,trueN]]\n",
                "df_cm = pd.DataFrame(array, [\"covid19\",\"non-covid19\"], [\"covid19\",\"non-covid19\"])\n",
                "sn.set(font_scale=1.4)\n",
                "\n",
                "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},cmap=\"Blues\") "
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "331Dvoig1Hj6"
            },
            "source": [
                "We finalize by visualizing the predictions of the model"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "hCnfbuny6DAl",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 1000,
                    "output_embedded_package_id": "1ZUmlRPLnHIxWm3rjFN8Wg1SfYT-MNQWD"
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1586736234439,
                    "user_tz": -60,
                    "elapsed": 25128
                },
                "outputId": "d0a5da73-8f6f-46fe-a8e8-008f0760ba55"
            },
            "source": [
                "import cv2\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "\n",
                "for index, probability in enumerate(pred):\n",
                "    image_path = TESTDATAPATH + \"/\" +eval_generator.filenames[index]\n",
                "    image = mpimg.imread(image_path)\n",
                "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "    pixels = np.array(image)\n",
                "    plt.imshow(pixels)\n",
                "    \n",
                "    print(eval_generator.filenames[index])\n",
                "    if probability > 0.5:\n",
                "        plt.title(\"%.2f\" % (probability[0]*100) + \"% Non-COVID19\")\n",
                "    else:\n",
                "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% COVID19\")\n",
                "    plt.show()"
            ],
            "execution_count": null,
            "outputs": []
        }
    ]
}